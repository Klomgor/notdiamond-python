interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, world! Does this async
      chat.completions.create call work?"}], "llm_providers": [{"provider": "openai",
      "model": "gpt-3.5-turbo", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-3.5-turbo-0125", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4", "is_custom": false, "context_length": null, "input_price": null, "output_price":
      null, "latency": null}, {"provider": "openai", "model": "gpt-4-0613", "is_custom":
      false, "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "gpt-4-1106-preview", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "gpt-4-turbo", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4-turbo-preview", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4-turbo-2024-04-09", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4o-2024-05-13", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4o-2024-08-06", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4o", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4o-mini-2024-07-18", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4o-mini", "is_custom": false, "context_length": null, "input_price": null,
      "output_price": null, "latency": null}, {"provider": "openai", "model": "gpt-4-0125-preview",
      "is_custom": false, "context_length": null, "input_price": null, "output_price":
      null, "latency": null}, {"provider": "openai", "model": "gpt-4.5-preview", "is_custom":
      false, "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "gpt-4.5-preview-2025-02-27", "is_custom":
      false, "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "o1-preview", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "o1-preview-2024-09-12", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "o1-mini", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "o1-mini-2024-09-12", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "chatgpt-4o-latest", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}], "metric": "accuracy", "max_model_depth":
      1, "hash_content": false}'
    headers:
      User-Agent:
      - Python-SDK/0.3.41
      content-type:
      - application/json
    method: POST
    uri: https://staging-api.notdiamond.ai/v2/modelRouter/modelSelect
  response:
    body:
      string: '{"providers":[{"provider":"openai","model":"gpt-4.5-preview"}],"session_id":"ef8076d3-d644-4aaf-8acb-f11baa184409"}'
    headers:
      CF-RAY:
      - 9258ae7aee804884-VIE
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 24 Mar 2025 19:47:40 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      Vary:
      - Accept-Encoding
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      content-length:
      - '115'
      rndr-id:
      - f1b77d4f-d58c-467c
      x-render-origin-server:
      - uvicorn
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, world! Does this async
      chat.completions.create call work?"}], "model": "gpt-4.5-preview"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, zstd
      connection:
      - keep-alive
      content-length:
      - '139'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - AsyncOpenAI/Python 1.68.2
      x-stainless-arch:
      - x64
      x-stainless-async:
      - async:asyncio
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.68.2
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.3
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"chatcmpl-BEi3rDcxF37GSguPOH8GLTGyRtMJm\",\n  \"object\":
        \"chat.completion\",\n  \"created\": 1742845663,\n  \"model\": \"gpt-4.5-preview-2025-02-27\",\n
        \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
        \"assistant\",\n        \"content\": \"Hi! It seems you're asking about the
        OpenAI Chat Completions API. Yes, you can make asynchronous API calls using
        OpenAI's Python SDK.\\n\\nHere's an example of how you might do this with
        OpenAI's Python SDK (v1.x and above):\\n\\n### Asynchronous example:\\n\\n```python\\nimport
        openai\\nimport asyncio\\n\\n# Set the API key (make sure you have the key
        configured)\\nopenai.api_key = \\\"YOUR_OPENAI_API_KEY\\\"\\n\\nasync def
        main():\\n    response = await openai.AsyncOpenAI().chat.completions.create(\\n
        \       model=\\\"gpt-3.5-turbo\\\",  # or your desired GPT model\\n        messages=[\\n
        \           {\\\"role\\\": \\\"system\\\", \\\"content\\\": \\\"You are a
        helpful assistant.\\\"},\\n            {\\\"role\\\": \\\"user\\\", \\\"content\\\":
        \\\"Hello, world! Does this async chat.completions.create call work?\\\"}\\n
        \       ]\\n    )\\n\\n    message = response.choices[0].message.content\\n
        \   print(f\\\"Assistant: {message}\\\")\\n\\nasyncio.run(main())\\n```\\n\\n###
        Important Notes:\\n\\n- Make sure you're using version 1.x or above, which
        introduced the async API (`openai.AsyncOpenAI()`).\\n- Don't forget to install
        the latest OpenAI Python SDK version if you haven't already:\\n\\n```bash\\npip
        install --upgrade openai\\n```\\n\\n### Conclusion:\\n\\nYes, the asynchronous
        call with `AsyncOpenAI().chat.completions.create` does indeed work with the
        SDK. Feel free to try the provided example to verify it.\",\n        \"refusal\":
        null,\n        \"annotations\": []\n      },\n      \"finish_reason\": \"stop\"\n
        \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 22,\n    \"completion_tokens\":
        311,\n    \"total_tokens\": 333,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\":
        0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\":
        {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\":
        0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\":
        \"default\",\n  \"system_fingerprint\": null\n}\n"
    headers:
      CF-RAY:
      - 9258ae810c1fdcbb-SOF
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Mon, 24 Mar 2025 19:48:24 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=gMuK5LSzptHKGP3RizGIANGVnZXWlnLTet9UXaqv_xo-1742845704-1.0.1.1-uPgt6i9MfBQFYR2TiXvultL_fDUcL8Us2GZ9fYrQ77qaKnIhgobOK20rBJldECuO49zED9pEQwtBmjGTB_my1xUbud8ck5w.5ITbt2tKuis;
        path=/; expires=Mon, 24-Mar-25 20:18:24 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=FihQ0_iN6tRZpU8XAl.I9cGjoOzdWFYyFtiPERh8PH0-1742845704939-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      content-length:
      - '2128'
      openai-organization:
      - not-diamond-bdz8cg
      openai-processing-ms:
      - '41868'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '2000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '1999981'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_672b778bfc8e619abe10bd2a2e8aa829
    status:
      code: 200
      message: OK
version: 1
