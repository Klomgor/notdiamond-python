interactions:
- request:
    body: '{"messages": [{"role": "user", "content": "Hello, world! Does this chat.completions.create
      call work?"}], "llm_providers": [{"provider": "openai", "model": "gpt-3.5-turbo",
      "is_custom": false, "context_length": null, "input_price": null, "output_price":
      null, "latency": null}, {"provider": "openai", "model": "gpt-3.5-turbo-0125",
      "is_custom": false, "context_length": null, "input_price": null, "output_price":
      null, "latency": null}, {"provider": "openai", "model": "gpt-4", "is_custom":
      false, "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "gpt-4-0613", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4-1106-preview", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4-turbo", "is_custom": false, "context_length": null,
      "input_price": null, "output_price": null, "latency": null}, {"provider": "openai",
      "model": "gpt-4-turbo-preview", "is_custom": false, "context_length": null,
      "input_price": null, "output_price": null, "latency": null}, {"provider": "openai",
      "model": "gpt-4-turbo-2024-04-09", "is_custom": false, "context_length": null,
      "input_price": null, "output_price": null, "latency": null}, {"provider": "openai",
      "model": "gpt-4o-2024-05-13", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4o-2024-08-06", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4o", "is_custom": false, "context_length": null, "input_price": null, "output_price":
      null, "latency": null}, {"provider": "openai", "model": "gpt-4o-mini-2024-07-18",
      "is_custom": false, "context_length": null, "input_price": null, "output_price":
      null, "latency": null}, {"provider": "openai", "model": "gpt-4o-mini", "is_custom":
      false, "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "gpt-4-0125-preview", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "gpt-4.1", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4.1-2025-04-14", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4.1-mini", "is_custom": false, "context_length": null,
      "input_price": null, "output_price": null, "latency": null}, {"provider": "openai",
      "model": "gpt-4.1-mini-2025-04-14", "is_custom": false, "context_length": null,
      "input_price": null, "output_price": null, "latency": null}, {"provider": "openai",
      "model": "gpt-4.1-nano", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4.1-nano-2025-04-14", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "o1-preview", "is_custom": false, "context_length": null, "input_price": null,
      "output_price": null, "latency": null}, {"provider": "openai", "model": "o1-preview-2024-09-12",
      "is_custom": false, "context_length": null, "input_price": null, "output_price":
      null, "latency": null}, {"provider": "openai", "model": "o1-mini", "is_custom":
      false, "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "o1-mini-2024-09-12", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}, {"provider": "openai", "model": "chatgpt-4o-latest", "is_custom": false,
      "context_length": null, "input_price": null, "output_price": null, "latency":
      null}], "metric": "accuracy", "max_model_depth": 1, "hash_content": false}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, zstd
      Connection:
      - keep-alive
      Content-Length:
      - '4091'
      User-Agent:
      - Python-SDK/0.4.3
      content-type:
      - application/json
    method: POST
    uri: https://staging-api.notdiamond.ai/v2/modelRouter/modelSelect
  response:
    body:
      string: '{"providers":[{"provider":"openai","model":"gpt-4.1"}],"session_id":"56b4b654-34dc-4265-bce2-90be073f90e3"}'
    headers:
      CF-RAY:
      - 947c7a31f9a2d0ef-SOF
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Fri, 30 May 2025 07:21:55 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      content-length:
      - '107'
      rndr-id:
      - f4bf7ac4-bfc8-45d5
      vary:
      - Accept-Encoding
      x-render-origin-server:
      - uvicorn
    status:
      code: 200
      message: OK
- request:
    body: '{"messages":[{"role":"user","content":"Hello, world! Does this chat.completions.create
      call work?"}],"model":"gpt-4.1"}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, zstd
      connection:
      - keep-alive
      content-length:
      - '119'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.70.0
      x-stainless-arch:
      - arm64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - MacOS
      x-stainless-package-version:
      - 1.70.0
      x-stainless-read-timeout:
      - '600'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.11.12
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"chatcmpl-BcoLrJTwjiR7bOHw9VilTxspYeZG8\",\n  \"object\":
        \"chat.completion\",\n  \"created\": 1748589715,\n  \"model\": \"gpt-4.1-2025-04-14\",\n
        \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
        \"assistant\",\n        \"content\": \"Hello, world! Yes, your usage of `chat.completions.create`
        suggests you're referring to the OpenAI API (or a compatible interface) for
        generating chat completions.\\n\\nIn code, a typical call might look like
        this (Python example):\\n\\n```python\\nresponse = client.chat.completions.create(\\n
        \   model=\\\"gpt-4\\\",\\n    messages=[{\\\"role\\\": \\\"user\\\", \\\"content\\\":
        \\\"Hello, world!\\\"}]\\n)\\nprint(response.choices[0].message.content)\\n```\\n\\nThis
        would send the \\\"Hello, world!\\\" message and return the assistant's reply.\\n\\n**If
        you're asking here whether such a call can be made from within this chat interface:**
        \ \\nNo, you cannot directly execute API calls here. This chat works on top
        of that API for you. But if you are writing your own code, your call structure
        looks correct! Let me know if you need an example for a specific language
        or platform.\",\n        \"refusal\": null,\n        \"annotations\": []\n
        \     },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n
        \ ],\n  \"usage\": {\n    \"prompt_tokens\": 21,\n    \"completion_tokens\":
        188,\n    \"total_tokens\": 209,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\":
        0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\":
        {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\":
        0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\":
        \"default\",\n  \"system_fingerprint\": \"fp_51e1070cf2\"\n}\n"
    headers:
      CF-RAY:
      - 947c7a39fcd784ce-VIE
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Fri, 30 May 2025 07:21:58 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=k3eCac1U3A9DmfIxtMQSUA4RSUomH4xsJQ4no1_6S.4-1748589718-1.0.1.1-bjrvwx98vy9rJEQYKzGmYUwikiLtgi0XwTgke29L0d3w78w4I19HvV6NdwLYWTRxRqJ2jJcvRpedru3Aa1PMyFNFffIPpCuy6ODwl3MUpfo;
        path=/; expires=Fri, 30-May-25 07:51:58 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=_ik2atN_5wQqcmqXjpwx4ucGG5JgZEBqcCxpCJB0Htk-1748589718680-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      content-length:
      - '1651'
      openai-organization:
      - not-diamond-bdz8cg
      openai-processing-ms:
      - '3034'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-envoy-upstream-service-time:
      - '3038'
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '30000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '29999983'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_3dc00e0324bfbdee75fdd10418e01bdb
    status:
      code: 200
      message: OK
version: 1
