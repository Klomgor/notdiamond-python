interactions:
- request:
    body: '{"messages": [{"role": "system", "content": "You are a world class programmer."},
      {"role": "user", "content": "Write a merge sort in Python"}], "llm_providers":
      [{"provider": "openai", "model": "gpt-3.5-turbo", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, {"provider":
      "openai", "model": "gpt-4", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4-1106-preview", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "openai", "model":
      "gpt-4-turbo-preview", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "anthropic", "model":
      "claude-3-haiku-20240307", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "anthropic", "model":
      "claude-3-sonnet-20240229", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}, {"provider": "anthropic", "model":
      "claude-3-opus-20240229", "is_custom": false, "context_length": null, "input_price":
      null, "output_price": null, "latency": null}], "metric": "accuracy", "max_model_depth":
      7, "hash_content": false, "tradeoff": "cost"}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, zstd
      Connection:
      - keep-alive
      Content-Length:
      - '1369'
      User-Agent:
      - Python-SDK/0.3.41
      content-type:
      - application/json
    method: POST
    uri: https://staging-api.notdiamond.ai/v2/modelRouter/modelSelect
  response:
    body:
      string: '{"providers":[{"provider":"openai","model":"gpt-4-1106-preview"}],"session_id":"d13fa799-3786-4b76-b4f0-466a6bbd3621"}'
    headers:
      CF-RAY:
      - 925cfce1f96d5b54-VIE
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 25 Mar 2025 08:20:14 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      content-length:
      - '118'
      rndr-id:
      - 597ded65-d52c-4db6
      vary:
      - Accept-Encoding
      x-render-origin-server:
      - uvicorn
    status:
      code: 200
      message: OK
- request:
    body: '{"messages": [{"content": "You are a world class programmer.", "role":
      "system"}, {"content": "Write a merge sort in Python", "role": "user"}], "model":
      "gpt-4-1106-preview", "n": 1, "stream": false, "temperature": 0.7}'
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate, zstd
      connection:
      - keep-alive
      content-length:
      - '219'
      content-type:
      - application/json
      host:
      - api.openai.com
      user-agent:
      - OpenAI/Python 1.68.2
      x-stainless-arch:
      - x64
      x-stainless-async:
      - 'false'
      x-stainless-lang:
      - python
      x-stainless-os:
      - Linux
      x-stainless-package-version:
      - 1.68.2
      x-stainless-read-timeout:
      - '120.0'
      x-stainless-retry-count:
      - '0'
      x-stainless-runtime:
      - CPython
      x-stainless-runtime-version:
      - 3.12.3
    method: POST
    uri: https://api.openai.com/v1/chat/completions
  response:
    body:
      string: "{\n  \"id\": \"chatcmpl-BEto7Y7TEg4zRzLnih9WJxUf90FvQ\",\n  \"object\":
        \"chat.completion\",\n  \"created\": 1742890815,\n  \"model\": \"gpt-4-1106-preview\",\n
        \ \"choices\": [\n    {\n      \"index\": 0,\n      \"message\": {\n        \"role\":
        \"assistant\",\n        \"content\": \"Certainly! Below is a Python implementation
        of the merge sort algorithm:\\n\\n```python\\ndef merge_sort(arr):\\n    if
        len(arr) > 1:\\n        mid = len(arr) // 2  # Finding the mid of the array\\n
        \       L = arr[:mid]  # Dividing the array elements into 2 halves\\n        R
        = arr[mid:]\\n\\n        merge_sort(L)  # Sorting the first half\\n        merge_sort(R)
        \ # Sorting the second half\\n\\n        i = j = k = 0\\n\\n        # Copy
        data to temp arrays L[] and R[]\\n        while i < len(L) and j < len(R):\\n
        \           if L[i] < R[j]:\\n                arr[k] = L[i]\\n                i
        += 1\\n            else:\\n                arr[k] = R[j]\\n                j
        += 1\\n            k += 1\\n\\n        # Checking if any element was left\\n
        \       while i < len(L):\\n            arr[k] = L[i]\\n            i += 1\\n
        \           k += 1\\n\\n        while j < len(R):\\n            arr[k] = R[j]\\n
        \           j += 1\\n            k += 1\\n\\n    return arr\\n\\n# Example
        usage:\\nif __name__ == \\\"__main__\\\":\\n    array = [12, 11, 13, 5, 6,
        7]\\n    print(\\\"Given array is:\\\", array)\\n    merge_sort(array)\\n
        \   print(\\\"Sorted array is:\\\", array)\\n```\\n\\nThis `merge_sort` function
        takes an array as input and sorts it in place. The function works by recursively
        dividing the array into two halves, sorting each half, and then merging the
        sorted halves together. The `merge_sort` function does not return a value
        because the sorting is done in place. However, the sorted array is accessible
        after calling the function.\",\n        \"refusal\": null,\n        \"annotations\":
        []\n      },\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n
        \   }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 24,\n    \"completion_tokens\":
        376,\n    \"total_tokens\": 400,\n    \"prompt_tokens_details\": {\n      \"cached_tokens\":
        0,\n      \"audio_tokens\": 0\n    },\n    \"completion_tokens_details\":
        {\n      \"reasoning_tokens\": 0,\n      \"audio_tokens\": 0,\n      \"accepted_prediction_tokens\":
        0,\n      \"rejected_prediction_tokens\": 0\n    }\n  },\n  \"service_tier\":
        \"default\",\n  \"system_fingerprint\": null\n}\n"
    headers:
      CF-RAY:
      - 925cfce6fc0589c3-SOF
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 25 Mar 2025 08:20:25 GMT
      Server:
      - cloudflare
      Set-Cookie:
      - __cf_bm=pKTc6RtmhT3_8wHFdO96i5VfsCsFpCJ.hgP7i2ci_RU-1742890825-1.0.1.1-9EnHjXq.y8.oIEASzSiTaU07t9WA9zZaLb0gY4VVtC1Z8Ye__XqsOTzzBGHxz6GQFWA1rJ9qkEEMCf4RRhkKswoQk4nSmtf4yUBcr1AoGmg;
        path=/; expires=Tue, 25-Mar-25 08:50:25 GMT; domain=.api.openai.com; HttpOnly;
        Secure; SameSite=None
      - _cfuvid=LcnqWlXFgiUNV1lAgy1MVO867TUpuzGVFGIyrNVAvDY-1742890825814-0.0.1.1-604800000;
        path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
      Transfer-Encoding:
      - chunked
      X-Content-Type-Options:
      - nosniff
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      content-length:
      - '2284'
      openai-organization:
      - not-diamond-bdz8cg
      openai-processing-ms:
      - '11061'
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      x-ratelimit-limit-requests:
      - '10000'
      x-ratelimit-limit-tokens:
      - '2000000'
      x-ratelimit-remaining-requests:
      - '9999'
      x-ratelimit-remaining-tokens:
      - '1999980'
      x-ratelimit-reset-requests:
      - 6ms
      x-ratelimit-reset-tokens:
      - 0s
      x-request-id:
      - req_3cce22647bbc619c6e2518e0850d655d
    status:
      code: 200
      message: OK
- request:
    body: '{"session_id": "d13fa799-3786-4b76-b4f0-466a6bbd3621", "provider": {"provider":
      "openai", "model": "gpt-4-1106-preview", "is_custom": false, "context_length":
      null, "input_price": null, "output_price": null, "latency": null}, "feedback":
      {"tokens_per_second": 33.58513760769427}}'
    headers:
      Accept:
      - '*/*'
      Accept-Encoding:
      - gzip, deflate, zstd
      Connection:
      - keep-alive
      Content-Length:
      - '279'
      User-Agent:
      - Python-SDK/0.3.41
      content-type:
      - application/json
    method: POST
    uri: https://staging-api.notdiamond.ai/v2/report/metrics/latency
  response:
    body:
      string: '{"detail":"requestID=8fb1e50d-98ff-4cb4, Session d13fa799-3786-4b76-b4f0-466a6bbd3621
        does not belong to user d6b6f4db-9cd9-4a33-b885-506685cd2d34."}'
    headers:
      CF-RAY:
      - 925cfd2e1ffa89c3-SOF
      Connection:
      - keep-alive
      Content-Type:
      - application/json
      Date:
      - Tue, 25 Mar 2025 08:20:26 GMT
      Server:
      - cloudflare
      Transfer-Encoding:
      - chunked
      alt-svc:
      - h3=":443"; ma=86400
      cf-cache-status:
      - DYNAMIC
      rndr-id:
      - 8fb1e50d-98ff-4cb4
      vary:
      - Accept-Encoding
      x-render-origin-server:
      - uvicorn
    status:
      code: 401
      message: Unauthorized
version: 1
